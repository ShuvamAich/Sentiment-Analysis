{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e6bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c80e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the training data\n",
    "imdb_data=pd.read_csv('IMDB Dataset.csv')\n",
    "print(imdb_data.shape)\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7291073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4968b97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "331ea3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = imdb_data[imdb_data.sentiment != 'unsup']\n",
    "imdb_data['sentiment'] = imdb_data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79bc561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61598642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text cleaning\n",
    " \n",
    "def clean(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z0-9]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "264d226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4343e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other review ha mention that after ...\n",
       "1        A wonder littl production. the film techniqu i...\n",
       "2        I thought thi wa a wonder way to spend time on...\n",
       "3        basic there' a famili where a littl boy (jake)...\n",
       "4        petter mattei' \"love in the time of money\" is ...\n",
       "5        probabl my all-tim favorit movie, a stori of s...\n",
       "6        I sure would like to see a resurrect of a up d...\n",
       "7        thi show wa an amazing, fresh & innov idea in ...\n",
       "8        encourag by the posit comment about thi film o...\n",
       "9        If you like origin gut wrench laughter you wil...\n",
       "10       phil the alien is one of those quirki film whe...\n",
       "11       I saw thi movi when I wa about 12 when it came...\n",
       "12       So im not a big fan of boll' work but then aga...\n",
       "13       the cast play shakespeare.shakespear lost.i ap...\n",
       "14       thi a fantast movi of three prison who becom f...\n",
       "15       kind of drawn in by the erot scenes, onli to r...\n",
       "16       some film just simpli should not be remade. th...\n",
       "17       thi movi made it into one of my top 10 most aw...\n",
       "18       I rememb thi film,it wa the first film i had w...\n",
       "19       An aw film! It must have been up against some ...\n",
       "20       after the success of die hard and it' sequel i...\n",
       "21       I had the terribl misfortun of have to view th...\n",
       "22       what an absolut stun movie, if you have 2.5 hr...\n",
       "23       first of all, let' get a few thing straight he...\n",
       "24       thi wa the worst movi I saw at worldfest and i...\n",
       "25       the karen carpent stori show a littl more abou...\n",
       "26       \"the cell\" is an exot masterpiece, a dizzi tri...\n",
       "27       thi film tri to be too mani thing all at once:...\n",
       "28       thi movi wa so frustrating. everyth seem energ...\n",
       "29       'war movie' is a hollywood genr that ha been d...\n",
       "                               ...                        \n",
       "49970    thi movi is a total dog. I found myself strain...\n",
       "49971    with sever name actor (lanc henrikson, david w...\n",
       "49972    the futur of fantasi never look so dark! chris...\n",
       "49973    the titl lead viewer to believ that thi is a f...\n",
       "49974    for the most part, \"michael\" is a disast Â– ten...\n",
       "49975    90 minut of mindy...mindi is a teas to boyfrie...\n",
       "49976    I saw the movi in the theater at it release, t...\n",
       "49977    dog bite dog isn't go to be for everyone, but ...\n",
       "49978    halloween is one of those movi that get you sk...\n",
       "49979    I saw thi with high expectations. come on, it ...\n",
       "49980    A stun film of high quality.appar base on true...\n",
       "49981    and I repeat, pleas do not see thi movie! thi ...\n",
       "49982    To be hones, I use to like thi show and watch ...\n",
       "49983    I love it, have been a fan of the origin serie...\n",
       "49984    hello it is I derrick cannon and I welcom you ...\n",
       "49985    imaginari hero is clearli the best film of the...\n",
       "49986    thi movi is a disgrac to the major leagu franc...\n",
       "49987    A remak of alejandro amenabar' abr lo ojos, bu...\n",
       "49988    when I first tune in on thi morn news, I thoug...\n",
       "49989    I got thi one a few week ago and love it! it' ...\n",
       "49990    lame, lame, lame!!! A 90-minut cringe-fest tha...\n",
       "49991    le visiteurs, the first movi about the mediev ...\n",
       "49992    john garfield play a marin who is blind by a g...\n",
       "49993    robert colomb ha two full-tim jobs. he' known ...\n",
       "49994    thi is your typic junk comedy.ther are almost ...\n",
       "49995    I thought thi movi did a down right good job. ...\n",
       "49996    bad plot, bad dialogue, bad acting, idiot dire...\n",
       "49997    I am a cathol taught in parochi elementari sch...\n",
       "49998    i'm go to have to disagre with the previou com...\n",
       "49999    No one expect the star trek movi to be high ar...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0fcfff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shuaich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "nltk.download('stopwords')\n",
    "stop=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02de90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "# function to remove stopwords\n",
    "def removestopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(removestopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9cc3f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.19528"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.review.apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e798324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 313s 8ms/step - loss: 0.3619 - accuracy: 0.8351 - val_loss: 0.2648 - val_accuracy: 0.8915\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 338s 8ms/step - loss: 0.2218 - accuracy: 0.9136 - val_loss: 0.2617 - val_accuracy: 0.8954\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 356s 9ms/step - loss: 0.1745 - accuracy: 0.9355 - val_loss: 0.2713 - val_accuracy: 0.8954\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 350s 9ms/step - loss: 0.1286 - accuracy: 0.9552 - val_loss: 0.3189 - val_accuracy: 0.8857\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 338s 8ms/step - loss: 0.0926 - accuracy: 0.9703 - val_loss: 0.3464 - val_accuracy: 0.8883\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(imdb_data['review'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(imdb_data['review'])\n",
    "\n",
    "maxlen = 600\n",
    "X = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y = imdb_data['sentiment']\n",
    "\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#batch_size = 100\n",
    "#epochs = 3\n",
    "history=model.fit(X,y, batch_size=100, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train on 40000 samples, validate on 10000 samples\n",
    "Epoch 1/5\n",
    "40000/40000 [==============================] - 313s 8ms/step - loss: 0.3619 - accuracy: 0.8351 - val_loss: 0.2648 - val_accuracy: 0.8915\n",
    "Epoch 2/5\n",
    "40000/40000 [==============================] - 338s 8ms/step - loss: 0.2218 - accuracy: 0.9136 - val_loss: 0.2617 - val_accuracy: 0.8954\n",
    "Epoch 3/5\n",
    "40000/40000 [==============================] - 356s 9ms/step - loss: 0.1745 - accuracy: 0.9355 - val_loss: 0.2713 - val_accuracy: 0.8954\n",
    "Epoch 4/5\n",
    "40000/40000 [==============================] - 350s 9ms/step - loss: 0.1286 - accuracy: 0.9552 - val_loss: 0.3189 - val_accuracy: 0.8857\n",
    "Epoch 5/5\n",
    "40000/40000 [==============================] - 338s 8ms/step - loss: 0.0926 - accuracy: 0.9703 - val_loss: 0.3464 - val_accuracy: 0.8883"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
